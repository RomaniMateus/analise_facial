{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:42:32.028977Z",
     "start_time": "2024-04-23T17:42:32.019929Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:42:32.049103Z",
     "start_time": "2024-04-23T17:42:32.031071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Coordinates of eye points that will be used to calculate the EAR (Eye Aspect Ratio)\n",
    "p_left_eye = [385, 380, 387, 373, 362, 263]\n",
    "p_right_eye = [160, 144, 158, 153, 33, 133]\n",
    "p_eyes = p_left_eye + p_right_eye\n",
    "\n",
    "p_mouth = [82, 87, 13, 14, 312, 317, 78, 308]"
   ],
   "id": "3b3553d803a6bc55",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:42:32.069114Z",
     "start_time": "2024-04-23T17:42:32.051388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# variables and constants used along the code\n",
    "EAR_THRESHOLD = 0.3\n",
    "MAR_THRESHOLD = 0.1\n",
    "TIME_THRESHOLD = 2\n",
    "sleeping = False\n",
    "blink_count = 0\n"
   ],
   "id": "1ab3652a71b47bc7",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:42:32.088979Z",
     "start_time": "2024-04-23T17:42:32.069636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_ear(face, right_eye: list, left_eye: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the EAR (Eye Aspect Ratio) of the face.\n",
    "    :param face: face mesh returned by MediaPipe\n",
    "    :param right_eye: list of eye points of the right eye\n",
    "    :param left_eye: list of eye points of the left eye\n",
    "    :return: EAR of the face\n",
    "    \"\"\"\n",
    "    \n",
    "    face_array = np.array([[coord.x, coord.y] for coord in face])\n",
    "    \n",
    "    left_face = face_array[left_eye, :]\n",
    "    right_face = face_array[right_eye, :]\n",
    "    \n",
    "    left_ear = (np.linalg.norm(left_face[0]-left_face[1]) + np.linalg.norm(left_face[2]-left_face[3])) / (2*np.linalg.norm(left_face[4]-left_face[5]))\n",
    "    \n",
    "    right_ear = (np.linalg.norm(right_face[0]-right_face[1]) + np.linalg.norm(right_face[2]-right_face[3])) / (2*np.linalg.norm(right_face[4]-right_face[5]))\n",
    "    \n",
    "    return (left_ear + right_ear) / 2"
   ],
   "id": "adf4b2e05b54e7fe",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:42:32.109129Z",
     "start_time": "2024-04-23T17:42:32.090707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_mar(face, mouth: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the MAR (Mouth Aspect Ratio) of the face.\n",
    "    :param face: face mesh returned by MediaPipe\n",
    "    :param mouth: list of mouth points\n",
    "    :return: MAR of the face\n",
    "    \"\"\"\n",
    "    \n",
    "    face_array = np.array([[coord.x, coord.y] for coord in face])\n",
    "    \n",
    "    mouth_face = face_array[mouth, :]\n",
    "    \n",
    "    mar = (np.linalg.norm(mouth_face[0]-mouth_face[1]) + np.linalg.norm(mouth_face[2]-mouth_face[3]) + np.linalg.norm(mouth_face[4]-mouth_face[5])) / (2*np.linalg.norm(mouth_face[6]-mouth_face[7]))\n",
    "    \n",
    "    return mar"
   ],
   "id": "96d9abc13a68726a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:42:46.709875Z",
     "start_time": "2024-04-23T17:42:32.111205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Defining:\n",
    "# 1. The drawing utilities of MediaPipe\n",
    "# 2. The FaceMesh model\n",
    "# 3. The video capture\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    # refine_landmarks=True ## Este parâmetro pode ser utilizado para detectar íris\n",
    ") as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        \n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        frame = cv.cvtColor(cv.flip(frame, 1), cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Send the frame to MediaPipe FaceMesh and get the result\n",
    "        results = face_mesh.process(frame)\n",
    "        \n",
    "        #Converting the image back to BGR\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            # Iterating over the landmarks detected\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Drawing the face landmarks on the frame                \n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=frame,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=1, circle_radius=1),\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "                )\n",
    "                        \n",
    "                face = face_landmarks.landmark\n",
    "                        \n",
    "                for id_coord, coord_xyz in enumerate(face):\n",
    "                    # Checking if the landmark is an eye point\n",
    "                    if id_coord in p_eyes:\n",
    "                        coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, width, height)\n",
    "                    \n",
    "                        cv.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
    "                    \n",
    "                    #Checking if the landmark is a mouth point\n",
    "                    if id_coord in p_mouth:\n",
    "                        coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, width, height)\n",
    "                    \n",
    "                        cv.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
    "                ear = calculate_ear(face, p_right_eye, p_left_eye)\n",
    "                mar = calculate_mar(face, p_mouth)\n",
    "                \n",
    "                # Provisionally displaying the EAR on the screen                \n",
    "                cv.rectangle(frame, (0,1), (290, 140), (58, 58, 55), -1)\n",
    "                cv.putText(frame, f'EAR: {round(ear, 2)}', (1, 24), cv.FONT_HERSHEY_DUPLEX, 0.9, (255, 255, 255), 2)\n",
    "                \n",
    "                # Provisionally displaying the MAR on the screen\n",
    "                cv.putText(frame, f'MAR: {round(mar, 2)}', (1, 50), cv.FONT_HERSHEY_DUPLEX, 0.9, (255, 255, 255), 2)\n",
    "                \n",
    "                # Checking if the EAR is below the threshold. If so, algorithm starts counting the time\n",
    "                if ear < EAR_THRESHOLD and mar < MAR_THRESHOLD:\n",
    "                    t_init = time.time() if not sleeping else t_init\n",
    "                    blink_count += 1 if not sleeping else blink_count\n",
    "                    sleeping = True\n",
    "                \n",
    "                # If the EAR is above the threshold, the algorithm stops counting the time    \n",
    "                if (sleeping and ear > EAR_THRESHOLD) or (ear <= EAR_THRESHOLD and mar >= MAR_THRESHOLD):\n",
    "                    sleeping = False\n",
    "                \n",
    "                t_end = time.time()\n",
    "                t = t_end - t_init if sleeping else 0\n",
    "                \n",
    "                cv.putText(frame, f'Blinks: {blink_count}', (1, 120), cv.FONT_HERSHEY_DUPLEX, 0.9, (255, 255, 255), 2)\n",
    "                cv.putText(frame, f'Time: {round(t, 3)}', (1, 80), cv.FONT_HERSHEY_DUPLEX, 0.9, (255, 255, 255), 2)\n",
    "                \n",
    "                # If the time is above the threshold, the algorithm displays a message on the screen\n",
    "                if t > TIME_THRESHOLD:\n",
    "                    cv.putText(frame, 'Drowsiness Detected', (1, 120), cv.FONT_HERSHEY_DUPLEX, 0.9, (0, 0, 255), 2)\n",
    "                \n",
    "        cv.imshow('MediaPipe FaceMesh', frame)\n",
    "        \n",
    "        # Break the loop when the 'q' key is pressed\n",
    "        if cv.waitKey(5) & 0xFF == ord('q'):\n",
    "            break   \n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ],
   "id": "13e9979314dc1bf",
   "outputs": [],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
